{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\" style=\"color:red;\">NEUROLIB fLDS DEMONSTRATION</h1> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook the `neurolib` implementation of fLDS is illustrated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/py35/lib/python3.5/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "import sys\n",
    "import pickle\n",
    "import os\n",
    "path = '/'.join(os.getcwd().split('/')[:-2])\n",
    "sys.path.append(path)\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing a dataset for neurolib-fLDS training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The analysis in this tutorial is run on a synthetic dataset of 80 trials, each consisting of 30-step sequences of 20D observations. This dataset was generated 'on top' of a 2D state space, evolving following a nonlinear law. In this tutorial the neurolib-fLDS implementation will be used to ascertain what can be expected of fLDS when handling a nonlinear dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fname = 'datadict_gaussianobs2D'\n",
    "with open(fname, 'rb') as f:\n",
    "  datadict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order for a `neurolib` **model** to use a dataset, whether for training or analysis, the dataset must be a python `dict` with specific keys corresponding to the Model nodes. For fLDS training, the neurolib requires the user to provide training and validation data with keys `train_Observation` and `valid_Observation` respectively.\n",
    "\n",
    "The loaded dataset is a python dict as the `neurolib` requires. However, in order to fit a specific `neurolib` model, the keys in the dataset should also match the expectations of that particular model. Typically, this will not be the case..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['Xtrain', 'Ytrain', 'Xtest', 'Yvalid', 'Xvalid', 'Ytest'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datadict.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`neurolib`'s fLDS expects the keys of the training and validation data to be set to `train_Observation` and `valid_Observation` respectively. This is done next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yshape (80, 30, 20)\n"
     ]
    }
   ],
   "source": [
    "dataset = {}\n",
    "Ytrain = datadict['Ytrain']\n",
    "Yshape = Ytrain.shape\n",
    "print(\"Yshape\", Yshape)\n",
    "dataset['train_Observation'] = Ytrain\n",
    "dataset['valid_Observation'] = datadict['Yvalid']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import fLDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neurolib.models.flds import fLDS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiating the fLDS Model class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The basic component of the neurolib is the **Model**, a class from which specific models like Regression, fLDS or VIND inherit.\n",
    "\n",
    "There are (currently) two **modes** by which a fLDS model can be defined, which are specified by the argument `mode`. One one hand, it is possible to initialize a brand new, untrained model. This is done by setting `mode='train'`; which is also the default mode. \n",
    "\n",
    "On the other hand, it is possible to *restore* an already trained model from disk. In what follows, we **build** a brand new fLDS model.\n",
    "\n",
    "In order to be built, a model typically must be provided with a few mandatory arguments. Moreover, the model *may* be provided with many optional arguments (over 30 in the case of fLDS), that range from hyperparameters to neural network architecture to options for training. For this basic tutorial we will simply use the defaults for all the optional arguments.\n",
    "\n",
    "Mandatory fLDS arguments for a brand new model are:\n",
    "\n",
    "`main_input_dim` :  The dimensionality of the data\n",
    "\n",
    "`state_dim` : The dimensionality of the latent space\n",
    "\n",
    "`max_steps` : The length of the data sequences.\n",
    "\n",
    "Additionally we will set the optional argument `save_on_valid_improvement` to `True` since we also want to restore the model later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ds_inputs ['LDS']\n",
      "Building all outputs,  Recognition\n",
      "\tBuilding loc,  Recognition\n",
      "\tBuilding prec,  Recognition\n",
      "\tBuilding main,  Recognition\n",
      "Building all outputs,  LDS\n",
      "\tBuilding A,  LDS\n",
      "\tBuilding loc,  LDS\n",
      "\tBuilding prec, scale,  LDS\n",
      "\tBuilding main,  LDS\n",
      "Building all outputs,  Posterior\n",
      "\tBuilding invscale, Posterior\n",
      "\tBuilding loc, Posterior\n",
      "\tBuilding main, Posterior\n",
      "Building all outputs,  Generative\n",
      "\tBuilding loc,  Generative\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/py35/lib/python3.5/site-packages/tensorflow/python/util/tf_inspect.py:75: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "  return _inspect.getargspec(target)\n",
      "/anaconda/envs/py35/lib/python3.5/site-packages/tensorflow/python/util/tf_inspect.py:75: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "  return _inspect.getargspec(target)\n",
      "/anaconda/envs/py35/lib/python3.5/site-packages/tensorflow/python/util/tf_inspect.py:75: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "  return _inspect.getargspec(target)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBuilding prec,  Generative\n",
      "\tBuilding main,  Generative\n",
      "\tBuilding loc,  Generative\n",
      "\t\tUpdating defaults, Generative with ['imain0']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/py35/lib/python3.5/site-packages/tensorflow/python/util/tf_inspect.py:75: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "  return _inspect.getargspec(target)\n",
      "/anaconda/envs/py35/lib/python3.5/site-packages/tensorflow/python/util/tf_inspect.py:75: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "  return _inspect.getargspec(target)\n",
      "/anaconda/envs/py35/lib/python3.5/site-packages/tensorflow/python/util/tf_inspect.py:75: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "  return _inspect.getargspec(target)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building entropy,  Posterior\n",
      "Building logprob,  Generative\n",
      "Building logprob,  LDS\n",
      "\tBuilding loc,  LDS\n",
      "\t\tUpdating defaults with ['imain0'] , LDS\n",
      "\n",
      "Scope: fLDS\n",
      "     0 fLDS/Recognition_loc/fully_connected/weights:0 [20, 64]\n",
      "     1 fLDS/Recognition_loc/fully_connected/biases:0 [64]\n",
      "     2 fLDS/Recognition_loc/fully_connected_1/weights:0 [64, 64]\n",
      "     3 fLDS/Recognition_loc/fully_connected_1/biases:0 [64]\n",
      "     4 fLDS/Recognition_loc/fully_connected_2/weights:0 [64, 2]\n",
      "     5 fLDS/Recognition_loc/fully_connected_2/biases:0 [2]\n",
      "     6 fLDS/Recognition_precision/fully_connected/weights:0 [20, 64]\n",
      "     7 fLDS/Recognition_precision/fully_connected/biases:0 [64]\n",
      "     8 fLDS/Recognition_precision/fully_connected_1/weights:0 [64, 64]\n",
      "     9 fLDS/Recognition_precision/fully_connected_1/biases:0 [64]\n",
      "     10 fLDS/Recognition_precision/fully_connected_2/weights:0 [64, 4]\n",
      "     11 fLDS/Recognition_precision/fully_connected_2/biases:0 [4]\n",
      "     12 fLDS/Prior_loc/loc:0 [2]\n",
      "     13 fLDS/Prior_scale/scale:0 [2, 2]\n",
      "     14 fLDS/LDS_A/A:0 [2, 2]\n",
      "     15 fLDS/LDS_prec/eye_init:0 [2, 2]\n",
      "     16 fLDS/Generative_loc/fully_connected/weights:0 [2, 64]\n",
      "     17 fLDS/Generative_loc/fully_connected/biases:0 [64]\n",
      "     18 fLDS/Generative_loc/fully_connected_1/weights:0 [64, 64]\n",
      "     19 fLDS/Generative_loc/fully_connected_1/biases:0 [64]\n",
      "     20 fLDS/Generative_loc/fully_connected_2/weights:0 [64, 20]\n",
      "     21 fLDS/Generative_loc/fully_connected_2/biases:0 [20]\n",
      "     22 fLDS/Generative_precision/lmbda_chol:0 [20, 20]\n",
      "     23 lr:0 []\n",
      "\n",
      "The following names are available for evaluation:\n",
      "\t Generative:loc\n",
      "\t Generative:logprob\n",
      "\t Generative:main\n",
      "\t Generative:prec\n",
      "\t Generative:prediction\n",
      "\t LDS:A\n",
      "\t LDS:loc\n",
      "\t LDS:logprob\n",
      "\t LDS:main\n",
      "\t LDS:prec\n",
      "\t LDS:scale\n",
      "\t Observation:main\n",
      "\t Posterior:entropy\n",
      "\t Posterior:invscaled\n",
      "\t Posterior:invscaleoffd\n",
      "\t Posterior:loc\n",
      "\t Posterior:main\n",
      "\t Prior:loc\n",
      "\t Prior:main\n",
      "\t Prior:scale\n",
      "\t Recognition:loc\n",
      "\t Recognition:main\n",
      "\t Recognition:prec\n",
      "\t StateSeq:main\n",
      "\t cost\n",
      "\t global_step\n",
      "\t train_op\n"
     ]
    }
   ],
   "source": [
    "max_steps, input_dim = Yshape[-2], Yshape[-1]\n",
    "flds = fLDS(main_input_dim=input_dim,\n",
    "            state_dim=[[2]],\n",
    "            max_steps=max_steps,\n",
    "            save_on_valid_improvement=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When a brand new model is initialized, its underlying tensorflow graph is built. Some information regarding the graph is displayed for the convenience of the user.\n",
    "\n",
    "- **Block number 1** tracks the process of building the Model graph. This is potentially useful to track whether the nodes and tensors are being constructed in the right order and for debugging.\n",
    "\n",
    "- **Block number 2** lists, once the model is built, all of its tensorflow TRAINABLE variables. For instance, it can be seen above that this fLDS architecture includes 4 neural networks, each 2 hidden layers deep.\n",
    "\n",
    "- **Block number 3** shows a list of **output names**. These correspond to tensors that are available for evaluation using the model's `eval` method. More on this in a moment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training a model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training a model is as easy as calling the model's `train` method. Mandatory arguments are a `dataset`, whose keys should follow neurolib's expectations, and the number of epochs `num_epochs`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flds.train(dataset, num_epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Names available for evaluation are listed when a Model is **built** or **restored**. For example, the dynamics matrix $A$ found by fLDS can be immediately evaluated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flds.eval(dataset, 'LDS:A', key='valid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The inferred state-space paths are also immediately available for evaluation from the name `'Posterior:loc'`. Let us plot then and see what fLDS has found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = flds.eval(dataset, 'Posterior:loc', key='train')\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "ax1 = fig.add_subplot(111)\n",
    "for i in range(0, 50):\n",
    "    ax1.plot(X[i,:,1], X[i,:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fLDS representation appears to show some fixed points, a feature that points to an underlying nonlinear dynamics. We don't expect a Linear Dynamical System to provide an accurate description of the evolution in this case. But fLDS still does well in representing the paths.\n",
    "\n",
    "Another thing that is suggested by these paths is that the underlying dynamics is indeed 2D. This is because 2D space is topologically \"tight\" for 1D paths. Hence, if the true dynamics was higher than 2D, one would expect paths to intertwine in a 2D representation of it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For convenience, fLDS models are also endowed with a method `eval_posterior` that returns the inferred paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = flds.eval_posterior(dataset, key='train')\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "ax1 = fig.add_subplot(111)\n",
    "for i in range(0, 50):\n",
    "    ax1.plot(X[i,:,1], X[i,:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to its nonlinear evolution, we do *not* expect the trained fLDS's dynamics to interpolate well this dataset. To test this, it is possible to compute the $kR^2$ on validation data by calling directly the `anal_kR2$ method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kR2 = flds.anal_kR2(dataset, key='valid')\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "ax1 = fig.add_subplot(111)\n",
    "ax1.set_xlabel('$k$', fontsize=20)\n",
    "ax1.set_ylabel(r'$R^2$', fontsize=20)\n",
    "ax1.set_ylim(ymin=0.0, ymax=1.0)\n",
    "ax1.plot(kR2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
